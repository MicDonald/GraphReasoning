{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d624278-209f-4b2c-871c-6a9b6f4e2649",
   "metadata": {},
   "source": [
    "# GraphReasoning: Scientific Discovery through Knowledge Extraction and Multimodal Graph-based Representation and Reasoning\n",
    "\n",
    "Markus J. Buehler, MIT, 2024 mbuehler@MIT.EDU\n",
    "\n",
    "### Example: GraphReasoning: Loading graph and graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9fc97f-9cc2-4728-9398-c5be7a2331ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cad71-ccc5-47d8-8701-aa9b766f0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "from huggingface_hub import hf_hub_download\n",
    "from GraphReasoning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6035b88-6be6-477a-b795-e9435e25f017",
   "metadata": {},
   "source": [
    "### Load graph and embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029dff92-f063-4ae2-b9af-b49fc6879295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Hugging Face repo\n",
    "repository_id = \"lamm-mit/GraphReasoning\"\n",
    "data_dir='./GRAPHDATA'    \n",
    "\n",
    "data_dir_output='./GRAPHDATA_OUTPUT/'\n",
    "\n",
    "graph_name='BioGraph.graphml'\n",
    "\n",
    "make_dir_if_needed(data_dir)\n",
    "make_dir_if_needed(data_dir_output)\n",
    "\n",
    "tokenizer_model=\"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(tokenizer_model, ) \n",
    "embedding_model = AutoModel.from_pretrained(tokenizer_model, ) \n",
    "\n",
    "filename = f\"{data_dir}/{graph_name}\"\n",
    "file_path = hf_hub_download(repo_id=repository_id, filename=filename,  local_dir='./')\n",
    "print(f\"File downloaded at: {file_path}\")\n",
    "\n",
    "graph_name=f'{data_dir}/{graph_name}'\n",
    "G = nx.read_graphml(graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bdfe1e-5641-4762-a3b0-e42e28359f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_file='BioGraph_embeddings_ge-large-en-v1.5.pkl'\n",
    "\n",
    "generate_new_embeddings=False\n",
    "if generate_new_embeddings:\n",
    "    node_embeddings = generate_node_embeddings(G, embedding_tokenizer, embedding_model, )\n",
    "    save_embeddings(node_embeddings, f'{data_dir}/{embedding_file}')\n",
    "    \n",
    "else:\n",
    "    filename = f\"{data_dir}/{embedding_file}\"\n",
    "    file_path = hf_hub_download(repo_id=repository_id, filename=filename, local_dir='./')\n",
    "    print(f\"File downloaded at: {file_path}\")\n",
    "\n",
    "    node_embeddings = load_embeddings(f'{data_dir}/{embedding_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f256c6-b48d-4cc1-b5b4-efd78ed7e107",
   "metadata": {},
   "source": [
    "### Load LLM: BioMixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fcdd6-318e-4739-b583-4a74da032e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import llama_cpp\n",
    "\n",
    "#m\n",
    "repository_id='lamm-mit/BioinspiredMixtral'\n",
    "filename='ggml-model-q5_K_M.gguf'\n",
    "file_path = hf_hub_download(repo_id=repository_id, filename=filename,  local_dir='./models/')\n",
    "\n",
    "chat_format=\"mistral-instruct\"\n",
    "\n",
    "llm = Llama(model_path=file_path,\n",
    "             n_gpu_layers=-1,verbose= True, #False,#False,\n",
    "             n_ctx=10000,\n",
    "             main_gpu=0,\n",
    "             chat_format=chat_format,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a2bc7-7ce0-4fc1-8982-af957f2a011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c2448-bb74-47ca-a74b-6bbb31c80008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_BioMixtral (system_prompt='You are a biomaterials cientist.', \n",
    "                         prompt=\"What is spider silk?\",temperature=0.333,\n",
    "                         max_tokens=10000, \n",
    "                         ):\n",
    "\n",
    "    if system_prompt==None:\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    else:\n",
    "        messages=[\n",
    "            {\"role\": \"system\",  \"content\": system_prompt, },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "    result=llm.create_chat_completion(\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "    return result['choices'][0]['message']['content']\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825d8a6-ff2c-48cb-ada5-acfacee3bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q='''What is graphene?'''\n",
    "start_time = time.time()\n",
    "res=generate_BioMixtral( system_prompt='You design materials.', \n",
    "         prompt=q, max_tokens=1024, temperature=0.3,  )\n",
    "\n",
    "print (res)\n",
    "deltat=time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % deltat)\n",
    "display (Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36872d4c-ea8c-428d-b32b-0987ccefc844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response, (best_node_1, best_similarity_1, best_node_2, best_similarity_2), path, path_graph, shortest_path_length, fname, graph_GraphML = find_path_and_reason(\n",
    "    G, \n",
    "    node_embeddings,\n",
    "    embedding_tokenizer, \n",
    "    embedding_model, \n",
    "    generate_BioMixtral, \n",
    "    data_dir=data_dir_output,\n",
    "    verbatim=True,\n",
    "    include_keywords_as_nodes=True,  # Include keywords in the graph analysis\n",
    "    keyword_1=\"collagen\",\n",
    "    keyword_2=\"copper\",\n",
    "    N_limit=9999,  # The limit for keywords, triplets, etc.\n",
    "    instruction='Develop a new research idea around collagen and copper.',\n",
    "    keywords_separator=', ',\n",
    "    graph_analysis_type='nodes and relations',\n",
    "    temperature=0.3, \n",
    "    inst_prepend='### ',  # Instruction prepend text\n",
    "    prepend='''You are given a set of information from a graph that describes the relationship \n",
    "               between materials, structure, properties, and properties. You analyze these logically \n",
    "               through reasoning.\\n\\n''',  # Prepend text for analysis\n",
    "    visualize_paths_as_graph=True,  # Whether to visualize paths as a graph\n",
    "    display_graph=True,  # Whether to display the graph\n",
    ")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f87f6d-9b8f-454f-8b7a-84806b8b22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, (best_node_1, best_similarity_1, best_node_2, best_similarity_2), path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
