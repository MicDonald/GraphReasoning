{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a4c4a0",
   "metadata": {},
   "source": [
    "# GraphReasoning: Scientific Discovery through Knowledge Extraction and Multimodal Graph-based Representation and Reasoning\n",
    "\n",
    "Markus J. Buehler, MIT, 2024 mbuehler@MIT.EDU\n",
    "\n",
    "### Example: GraphReasoning: Loading graph and graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336e744c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# device='cuda:0'\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "from huggingface_hub import hf_hub_download\n",
    "from GraphReasoning import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee71b51-cfa6-4dca-aa55-de6b48f19c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatim=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e892a7b-ec8c-4385-b429-d3c10c49ec52",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35aa0f7e-3597-4273-9a62-01b91fec153a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 /home/mkychsu/pool/TSMC/GraphRAG/dry-etching-technology-for-semiconductors_compress.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "doc_data_dir = '/home/mkychsu/pool/TSMC/GraphRAG/'\n",
    "# doc_list = []\n",
    "doc_list=[f'{doc_data_dir}dry-etching-technology-for-semiconductors_compress.txt',\n",
    "          f'{doc_data_dir}plasma-etching-an-introduction_compress.txt',\n",
    "          f'{doc_data_dir}handbook-of-silicon-wafer-cleaning-technology-third-edition_compress.txt',\n",
    "          f'{doc_data_dir}Ultraclean Surface Processing of Silicon Wafers - PDF Free Download.txt',\n",
    "          f'{doc_data_dir}Atomic Layer Processing_semiconductor.txt'   \n",
    "]\n",
    "\n",
    "doc_list_all=sorted(glob.glob(f'{doc_data_dir}/*.txt'))\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "for i, doc in enumerate(doc_list_all):\n",
    "    if doc in doc_list:\n",
    "        continue\n",
    "    try:\n",
    "        temp_doc = doc_list_all[i+1]\n",
    "        sim = similar(temp_doc.lower(), doc.lower())\n",
    "        if sim < 0.9:\n",
    "            doc_list.append(doc)\n",
    "        else:\n",
    "            if abs(os.stat(doc).st_size - os.stat(temp_doc).st_size)/os.stat(doc).st_size < 1e-3:\n",
    "                print(f'{i}:{sim},\\n {doc} \\n {temp_doc}')\n",
    "            else:\n",
    "                doc_list.append(doc)\n",
    "    except:\n",
    "        pass\n",
    "print(len(doc_list),doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b5fe5fb-49b6-4ccd-a4bd-c78028252ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mkychsu/pool/TSMC/GraphRAG/dry-etching-technology-for-semiconductors_compress.txt',\n",
       " '/home/mkychsu/pool/TSMC/GraphRAG/plasma-etching-an-introduction_compress.txt',\n",
       " '/home/mkychsu/pool/TSMC/GraphRAG/handbook-of-silicon-wafer-cleaning-technology-third-edition_compress.txt',\n",
       " '/home/mkychsu/pool/TSMC/GraphRAG/Ultraclean Surface Processing of Silicon Wafers - PDF Free Download.txt',\n",
       " '/home/mkychsu/pool/TSMC/GraphRAG/Atomic Layer Processing_semiconductor.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9780425d-3b58-4b4d-9175-5a0631b66117",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# doc_data_dir = '/home/mkychsu/pool/TSMC/dataset/'\n",
    "# doc_list=[f'{doc_data_dir}dry-etching-technology-for-semiconductors_compress.pdf',\n",
    "#           f'{doc_data_dir}plasma-etching-an-introduction_compress.pdf',\n",
    "#           f'{doc_data_dir}handbook-of-silicon-wafer-cleaning-technology-third-edition_compress.pdf',\n",
    "#           f'{doc_data_dir}Ultraclean Surface Processing of Silicon Wafers - PDF Free Download.pdf',\n",
    "#           f'{doc_data_dir}Atomic Layer Processing_semiconductor.pdf'   \n",
    "# ]\n",
    "\n",
    "# doc_list_all=sorted(glob.glob(f'{doc_data_dir}*.pdf'))\n",
    "\n",
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# def similar(a, b):\n",
    "#     return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# for i, doc in enumerate(doc_list_all):\n",
    "#     if doc in doc_list:\n",
    "#         continue\n",
    "#     try:\n",
    "#         temp_doc = doc_list_all[i+1]\n",
    "#         sim = similar(temp_doc.lower(), doc.lower())\n",
    "#         if sim < 0.9:\n",
    "#             doc_list.append(doc)\n",
    "#         else:\n",
    "#             if abs(os.stat(doc).st_size - os.stat(temp_doc).st_size)/os.stat(doc).st_size < 1e-3:\n",
    "#                 print(f'{i}:{sim},\\n {doc} \\n {temp_doc}')\n",
    "#             else:\n",
    "#                 doc_list.append(doc)\n",
    "#     except:\n",
    "#         pass\n",
    "# print(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c542cb2b-55fb-4490-ac88-665b0a890e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_to_check = doc_list[0].split('/')\n",
    "# file_to_check[-2] = 'dataset_textbook'\n",
    "# file_to_check[-1]=f'0.txt'\n",
    "# file_to_check='/'.join(file_to_check)\n",
    "# file_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ac7bf8-8764-450f-ba0c-90132595ea1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists(file_to_check):\n",
    "#     from langchain_community.document_loaders import PyPDFium2Loader as PDFLoader\n",
    "#     for i, doc in enumerate(doc_list[:5]):\n",
    "#         try:\n",
    "#             doc_pages = PDFLoader(doc).load_and_split()\n",
    "#             txt=''\n",
    "#             for page in doc_pages:\n",
    "#                 txt += page.page_content.replace('\\n', ' ')\n",
    "#             with open(f'/home/mkychsu/pool/TSMC/dataset_textbook/{i}.txt', 'w') as f:\n",
    "#                 f.write(f'{txt}')\n",
    "#                 f.close()\n",
    "#         except: # Exception as e:\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a54e02",
   "metadata": {},
   "source": [
    "### Load the LLM and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf447a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hugging Face repo\n",
    "# repository_id = \"lamm-mit/GraphReasoning\"\n",
    "data_dir='./GRAPHDATA_TSMC'    \n",
    "data_dir_output='./GRAPHDATA_TSMC_OUTPUT/'\n",
    "\n",
    "# data_dir_output='./GRAPHDATA_OUTPUT/'\n",
    "# graph_name='BioGraph.graphml'\n",
    "\n",
    "# make_dir_if_needed(data_dir)\n",
    "# make_dir_if_needed(data_dir_output)\n",
    "\n",
    "tokenizer_model=\"BAAI/bge-large-en-v1.5\"\n",
    "# tokenizer_model=\"f'/home/mkychsu/pool/llm/Mistral-7B-Instruct-v0.3/tokenizer.json\"\n",
    "\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(tokenizer_model, ) \n",
    "embedding_model = AutoModel.from_pretrained(tokenizer_model, )\n",
    "# embedding_model.to('cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a886615-4c05-4be8-80df-fc8476e21c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = f\"{data_dir}/{graph_name}\"\n",
    "# file_path = hf_hub_download(repo_id=repository_id, filename=filename,  local_dir='./')\n",
    "# print(f\"File downloaded at: {file_path}\")\n",
    "\n",
    "# graph_name=f'{data_dir}/{graph_name}'\n",
    "# G = nx.read_graphml(graph_name)\n",
    "\n",
    "# repository_id='MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF'\n",
    "# filename='Mistral-7B-Instruct-v0.3Q8_0.gguf'\n",
    "\n",
    "repository_id='bartowski/Mistral-7B-Instruct-v0.3-GGUF'\n",
    "filename='Mistral-7B-Instruct-v0.3-Q8_0.gguf'\n",
    "\n",
    "file_path = hf_hub_download(repo_id=repository_id, filename=filename,  local_dir='/home/mkychsu/pool/llm')\n",
    "# file_path = f'{model}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e1660",
   "metadata": {},
   "source": [
    "### Load LLM: clean Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc83101",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: Tesla V100S-PCIE-32GB, compute capability 7.0, VMM: yes\n",
      "llama_model_loader: loaded meta data with 29 key-value pairs and 291 tensors from /home/mkychsu/pool/llm/Mistral-7B-Instruct-v0.3-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Mistral-7B-Instruct-v0.3\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32768\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32768]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32768]   = [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                      quantize.imatrix.file str              = /models/Mistral-7B-Instruct-v0.3-GGUF...\n",
      "llama_model_loader: - kv  26:                   quantize.imatrix.dataset str              = /training_data/calibration_data.txt\n",
      "llama_model_loader: - kv  27:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  28:              quantize.imatrix.chunks_count i32              = 228\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 1027/32768 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32768\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 7.25 B\n",
      "llm_load_print_meta: model size       = 7.17 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Mistral-7B-Instruct-v0.3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 781 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   136.00 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  7209.02 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10000\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1250.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1250.00 MiB, K (f16):  625.00 MiB, V (f16):  625.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   668.53 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    27.54 MiB\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "# import llama_cpp\n",
    "\n",
    "llm = Llama(model_path=file_path,\n",
    "             n_gpu_layers=-1,verbose= True, #False,#False,\n",
    "             n_ctx=10000,\n",
    "             main_gpu=0,\n",
    "             # chat_format='mistral-instruct',\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76f24ed-e4c3-4226-8dff-b2568f6294bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5db975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_Mistral (system_prompt='You are a semiconductor engineer. Try to find the clear relationship in the provided information', \n",
    "                         prompt=\"How to make silicon into chip?\",temperature=0.333,\n",
    "                         max_tokens=8192, \n",
    "                         ):\n",
    "\n",
    "    if system_prompt==None:\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    else:\n",
    "        messages=[\n",
    "            {\"role\": \"system\",  \"content\": system_prompt, },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "    result=llm.create_chat_completion(\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "    return result['choices'][0]['message']['content']\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677eb899",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# q='''Explain how semiconductor is made in a very professional way with as much detail as possible'''\n",
    "# start_time = time.time()\n",
    "# res=generate_Mistral( system_prompt='You are an expert in semiconductor fields. Try to find the clear relation in the provided information. Skip the authorship information if it is not relevant', \n",
    "#          prompt=q, max_tokens=1024, temperature=0.3,  )\n",
    "\n",
    "# print (res)\n",
    "# deltat=time.time() - start_time\n",
    "# print(\"--- %s seconds ---\" % deltat)\n",
    "# display (Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e673800-9a97-49e1-aef0-73ad55ff9dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graph_HTML, graph_GraphML, G, net, output_pdf = make_graph_from_text(res, generate_Mistral,\n",
    "#                                                                      chunk_size=1000,chunk_overlap=200,\n",
    "#                                                                      do_distill=True, data_dir='temp', verbatim=True,\n",
    "#                                                                      repeat_refine=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aae8bf5-a710-4c43-9e53-a1fa818de30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM']='true'\n",
    "\n",
    "embedding_file='TSMC_KG_mistral_instruct_v0.3.pkl'\n",
    "generate_new_embeddings=True\n",
    "\n",
    "if os.path.exists(f'{data_dir}/{embedding_file}'):\n",
    "    generate_new_embeddings=False\n",
    "\n",
    "if generate_new_embeddings:\n",
    "    node_embeddings = generate_node_embeddings(G, embedding_tokenizer, embedding_model, )\n",
    "    save_embeddings(node_embeddings, f'{data_dir}/{embedding_file}')\n",
    "    \n",
    "else:\n",
    "    filename = f\"{data_dir}/{embedding_file}\"\n",
    "    # file_path = hf_hub_download(repo_id=repository_id, filename=filename, local_dir='./')\n",
    "    # print(f\"File downloaded at: {file_path}\")\n",
    "    node_embeddings = load_embeddings(f'{data_dir}/{embedding_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c1e53-9ed2-4816-9371-24f442ba4421",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a graph fragment to merge: 0: /home/mkychsu/pool/TSMC/GraphRAG/dry-etching-technology-for-semiconductors_compress.txt.\n",
      "Generating a knowledge graph from /home/mkychsu/pool/TSMC/GraphRAG/plasma-etching-an-introduction_compress.txt\n",
      "Number of chunks =  1153\n",
      ".[{'node_1': 'Plasma', 'node_2': 'Ionized Gas', 'edge': 'is'}, {'node_1': 'Plasma', 'node_2': 'Materials', 'edge': 'interacts with'}, {'node_1': 'Materials', 'node_2': 'Semiconductors', 'edge': 'one type of'}, {'node_1': 'Materials', 'node_2': 'Polymers', 'edge': 'another type of'}, {'node_1': 'Materials', 'node_2': 'Gases', 'edge': 'another type of'}, {'node_1': 'Plasma', 'node_2': 'Microelectronics', 'edge': 'important in'}, {'node_1': 'Plasma', 'node_2': 'Plasma Physics', 'edge': 'important in'}, {'node_1': 'Plasma', 'node_2': 'Chemical Engineering', 'edge': 'important in'}, {'node_1': 'Plasma', 'node_2': 'Fusion Energy', 'edge': 'important in'}, {'node_1': 'International Research Team', 'node_2': 'Experts', 'edge': 'consists of'}, {'node_1': 'International Research Team', 'node_2': 'Princeton University', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'AT&T Bell Laboratories', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'University of Bari', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'IBM Almaden Research Center', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'Kernforschungsanlage Julich GmbH', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'Nagoya University', 'edge': 'affiliated with'}, {'node_1': 'International Research Team', 'node_2': 'Culham Laboratory', 'edge': 'affiliated with'}, {'node_1': 'Plasma Etching', 'node_2': 'Microelectronics', 'edge': 'essential process in'}, {'node_1': 'Plasma Etching', 'node_2': 'Patterns', 'edge': 'used for creating'}, {'node_1': 'Plasma Etching', 'node_2': 'Semiconductor Wafers', 'edge': 'on'}, {'node_1': 'Publication', 'node_2': 'Academic Press', 'edge': 'publisher of'}, {'node_1': 'Scientific, Technical, and Medical Content', 'node_2': 'Academic Press', 'edge': 'publisher of'}, {'node_1': 'Volume', 'node_2': 'Plasma Etching', 'edge': 'dedicated to'}, {'node_1': 'Editors', 'node_2': 'Dennis M. Manos', 'edge': 'edited by'}, {'node_1': 'Editors', 'node_2': 'Daniel L. Flamm', 'edge': 'edited by'}]\n",
      ".[{'node_1': 'plasma etching', 'node_2': 'etching process', 'edge': 'is'}, {'node_1': 'plasma etching', 'node_2': 'surface modification', 'edge': 'can be used for'}, {'node_1': 'plasma etching', 'node_2': 'cleaning', 'edge': 'can be used for'}, {'node_1': 'plasma etching', 'node_2': 'patterning', 'edge': 'can be used for'}, {'node_1': 'plasma', 'node_2': 'materials interaction', 'edge': 'involves'}, {'node_1': 'publication', 'node_2': 'comprehensive review', 'edge': 'is'}, {'node_1': 'publication', 'node_2': 'book', 'edge': 'is a type of'}, {'node_1': 'book', 'node_2': \"Princeton University's Plasma Physics Laboratory\", 'edge': 'authored by'}, {'node_1': 'book', 'node_2': 'AT&T Bell Laboratories', 'edge': 'co-authored by'}, {'node_1': 'publication', 'node_2': 'Academic Press, Inc.', 'edge': 'is published by'}, {'node_1': 'publishing locations', 'node_2': 'San Diego, California', 'edge': 'one of'}, {'node_1': 'publishing locations', 'node_2': 'London, England', 'edge': 'one of'}, {'node_1': 'publication', 'node_2': 'acid-free paper', 'edge': 'is printed on'}, {'node_1': 'publication', 'node_2': 'copyright laws', 'edge': 'is protected by'}, {'node_1': 'reproduction', 'node_2': 'part of the publication', 'edge': 'no part of is allowed to be reproduced or transmitted without permission from the publisher'}, {'node_1': 'publication', 'node_2': 'scientific literature', 'edge': 'is a part of'}]\n",
      ".[{'node_1': 'Plasma Etching', 'node_2': 'Material Modification Techniques', 'edge': 'is a type of'}, {'node_1': 'Plasma Etching', 'node_2': 'Electronics Industry', 'edge': 'applied in'}, {'node_1': 'Plasma Etching', 'node_2': 'Semiconductor Industry', 'edge': 'applied in'}, {'node_1': 'Plasma Etching', 'node_2': 'Microfabrication', 'edge': 'applied in'}, {'node_1': 'Dennis Manos', 'node_2': 'Authors', 'edge': 'one of the authors'}, {'node_1': 'Daniel Flamm', 'node_2': 'Authors', 'edge': 'one of the authors'}, {'node_1': 'Samuel Cohen', 'node_2': 'Authors', 'edge': 'one of the authors'}, {'node_1': 'James Harper', 'node_2': 'Authors', 'edge': 'one of the authors'}, {'node_1': 'University of California at Berkeley', 'node_2': 'Institutions', 'edge': 'affiliation of authors'}, {'node_1': 'AT&T Bell Laboratories', 'node_2': 'Institutions', 'edge': 'affiliation of authors'}, {'node_1': 'Princeton University', 'node_2': 'Institutions', 'edge': 'affiliation of authors'}, {'node_1': 'IBM Thomas J. Watson Research Center', 'node_2': 'Institutions', 'edge': 'affiliation of authors'}, {'node_1': 'Academic Press Limited', 'node_2': 'Publisher', 'edge': 'published by'}, {'node_1': 'Plasma Physics', 'node_2': 'Topics', 'edge': 'covered in the book'}, {'node_1': 'Reactive Gases for Plasma Etching', 'node_2': 'Topics', 'edge': 'covered in the book'}, {'node_1': 'Plasma Etching Mechanisms', 'node_2': 'Topics', 'edge': 'covered in the book'}, {'node_1': 'Equipment Design for Plasma Etching', 'node_2': 'Topics', 'edge': 'covered in the book'}, {'node_1': 'Applications of Plasma Etching', 'node_2': 'Topics', 'edge': 'covered in the book'}, {'node_1': 'Researchers', 'node_2': 'Audience', 'edge': 'intended for'}, {'node_1': 'Engineers', 'node_2': 'Audience', 'edge': 'intended for'}, {'node_1': 'Students', 'node_2': 'Audience', 'edge': 'intended for'}, {'node_1': 'Academic Press Limited', 'node_2': 'Publication Details', 'edge': 'published by'}, {'node_1': 'United States of America', 'node_2': 'Publication Details', 'edge': 'printed in'}, {'node_1': 'Series: Plasma-Materials Interactions', 'node_2': 'Publication Details', 'edge': 'part of the series'}]\n",
      ".[{'node_1': 'plasma chemistry', 'node_2': 'non-equilibrium plasma', 'edge': 'studies'}, {'node_1': 'plasma chemistry', 'node_2': 'dry processing', 'edge': 'applies in'}, {'node_1': 'dry processing', 'node_2': 'wet processing', 'edge': 'does not involve'}, {'node_1': 'plasma chemistry', 'node_2': 'industrial applications', 'edge': 'has potential for'}, {'node_1': 'book', 'node_2': 'lecture series at various institutions', 'edge': 'presents an overview of'}, {'node_1': 'book', 'node_2': 'diverse educational backgrounds', 'edge': 'cater to individuals with'}, {'node_1': 'book', 'node_2': 'beginners', 'edge': 'intended for'}, {'node_1': 'book', 'node_2': 'experienced professionals', 'edge': 'intended for'}, {'node_1': 'book', 'node_2': 'comprehensive introduction to dry plasma chemistry', 'edge': 'aims to provide'}, {'node_1': 'plasma chemistry', 'node_2': 'James M. E. Harper (IBM Thomas J. Watson Research Center)', 'edge': 'authored by'}, {'node_1': 'plasma chemistry', 'node_2': 'G. K. Herb (AT&T Bell Laboratories)', 'edge': 'authored by'}, {'node_1': 'plasma chemistry', 'node_2': \"Dennis M. Manos (Princeton University's Plasma Physics Laboratory)\", 'edge': 'authored by'}, {'node_1': 'plasma chemistry', 'node_2': 'Ala R. Reinberg (Perkin-Elmer Corporation)', 'edge': 'authored by'}, {'node_1': 'book', 'node_2': \"Princeton University's Plasma Physics Laboratory\", 'edge': 'authored by an expert from'}, {'node_1': 'book', 'node_2': 'IBM Thomas J. Watson Research Center', 'edge': 'authored by an expert from'}, {'node_1': 'book', 'node_2': 'AT&T Bell Laboratories', 'edge': 'authored by an expert from'}, {'node_1': 'book', 'node_2': 'Perkin-Elmer Corporation', 'edge': 'authored by an expert from'}, {'node_1': 'book', 'node_2': 'tutorial style', 'edge': 'adopts'}, {'node_1': 'tutorial style', 'node_2': 'comprehension', 'edge': 'intended to facilitate'}, {'node_1': 'book', 'node_2': 'theoretical applications', 'edge': 'covers various aspects of, providing an overview of'}, {'node_1': 'book', 'node_2': 'practical applications', 'edge': 'covers various aspects of, providing an overview of'}]\n",
      ".[{'node_1': 'Plasma Etching', 'node_2': 'Microelectronics', 'edge': 'applies to'}, {'node_1': 'Plasma Etching', 'node_2': 'Materials Science', 'edge': 'applies to'}, {'node_1': 'Plasma Etching', 'node_2': 'Surface Engineering', 'edge': 'applies to'}, {'node_1': 'Fundamentals of Plasma Etching', 'node_2': 'Introduction to Plasma Etching', 'edge': 'provides an overview of'}, {'node_1': 'Fundamentals of Plasma Etching', 'node_2': 'Main Concepts', 'edge': 'introduces'}, {'node_1': 'Fundamentals of Plasma Etching', 'node_2': 'Terminology', 'edge': 'defines'}, {'node_1': 'Fundamentals of Plasma Etching', 'node_2': 'Fundamental Definitions', 'edge': 'presents'}, {'node_1': 'Plasma Etching', 'node_2': 'Plasma Physics', 'edge': 'relies on principles of'}, {'node_1': 'Plasma Physics', 'node_2': 'Charged Particles', 'edge': 'involves behavior of'}, {'node_1': 'Plasma Etching', 'node_2': 'Reaction Kinetics', 'edge': 'relies on understanding of'}, {'node_1': 'Plasma Etching', 'node_2': 'Plasma-Materials Interactions', 'edge': 'involves'}, {'node_1': 'Plasma Etching', 'node_2': 'Microelectronics Manufacturing', 'edge': 'applies to'}, {'node_1': 'Plasma Etching', 'node_2': 'Semiconductor Manufacturing', 'edge': 'applies to'}, {'node_1': 'Book', 'node_2': 'Academic Press Series', 'edge': 'inspired by'}, {'node_1': 'Plasma Etching', 'node_2': 'Novices', 'edge': 'suitable for learning about'}, {'node_1': 'Plasma Etching', 'node_2': 'Experienced Professionals', 'edge': 'provides in-depth treatments for'}, {'node_1': 'Book', 'node_2': 'Tutorial-Style Approach', 'edge': 'adopts'}, {'node_1': 'Book', 'node_2': 'Comprehensive Textbook', 'edge': 'aims to be'}]\n",
      ".[{'node_1': 'plasma', 'node_2': 'ionized gas', 'edge': 'is'}, {'node_1': 'plasma', 'node_2': 'industrial processes', 'edge': 'used in'}, {'node_1': 'plasma', 'node_2': 'silicon etching', 'edge': 'used for'}, {'node_1': 'positive ions', 'node_2': 'plasma', 'edge': 'component of'}, {'node_1': 'negative electrons', 'node_2': 'plasma', 'edge': 'component of'}, {'node_1': 'neutral particles', 'node_2': 'plasma', 'edge': 'component of'}, {'node_1': 'reactive species', 'node_2': 'plasma', 'edge': 'generated in'}, {'node_1': 'free radicals', 'node_2': 'reactive species', 'edge': 'type of'}, {'node_1': 'ions', 'node_2': 'reactive species', 'edge': 'type of'}, {'node_1': 'silicon surface', 'node_2': 'reactive species', 'edge': 'reacts with'}, {'node_1': 'photoresists', 'node_2': 'materials used in lithography processes', 'edge': 'used for selectively protecting or exposing silicon surface during etching'}, {'node_1': 'pressure', 'node_2': 'etch rate, selectivity, and uniformity', 'edge': 'influences'}, {'node_1': 'higher pressure', 'node_2': 'unwanted side reactions', 'edge': 'tends to lead to'}, {'node_1': 'plasma reactor design', 'node_2': 'performance of etching process', 'edge': 'significantly impacts'}, {'node_1': 'power input', 'node_2': 'plasma reactor design', 'edge': 'factor in'}, {'node_1': 'gas flow', 'node_2': 'plasma reactor design', 'edge': 'factor in'}, {'node_1': 'geometry', 'node_2': 'plasma reactor design', 'edge': 'factor in'}, {'node_1': 'power coupling efficiency', 'node_2': 'high-quality etching results', 'edge': 'essential for achieving'}, {'node_1': 'plasma stability', 'node_2': 'etch rates and uniformity', 'edge': 'crucial for maintaining'}, {'node_1': 'plasma scaling', 'node_2': 'laboratory-scale to industrial-scale', 'edge': 'understanding how to scale up is essential for practical applications'}]\n",
      ".[{'node_1': 'plasma reactors', 'node_2': 'pressure', 'edge': 'influenced by'}, {'node_1': 'plasma reactors', 'node_2': 'frequency', 'edge': 'influenced by'}, {'node_1': 'plasma reactors', 'node_2': 'temperature', 'edge': 'influenced by'}, {'node_1': 'particles', 'node_2': 'pressure', 'edge': 'density of'}, {'node_1': 'plasma', 'node_2': 'behavior', 'edge': 'affects'}, {'node_1': 'electric field', 'node_2': 'excited species', 'edge': 'determines the type of present in the plasma'}, {'node_1': 'reaction rates', 'node_2': 'temperature', 'edge': 'controls'}, {'node_1': 'plasma reactors (with magnetic fields)', 'node_2': 'Chapter 3', 'edge': 'focus of'}, {'node_1': 'complex plasma processing terminology', 'node_2': 'plasma processing', 'edge': 'related to'}, {'node_1': 'readers', 'node_2': 'understanding of plasma processing', 'edge': 'equipped with'}, {'node_1': 'Chapter 4', 'node_2': 'diagnostic techniques', 'edge': 'covers'}, {'node_1': 'diagnostic techniques', 'node_2': 'process plasma research', 'edge': 'used in'}, {'node_1': 'diagnostic techniques', 'node_2': 'ULSI device production', 'edge': 'used in'}, {'node_1': 'electrostatic probes', 'node_2': 'diagnostic techniques', 'edge': 'includes'}, {'node_1': 'emission spectroscopy', 'node_2': 'diagnostic techniques', 'edge': 'includes'}, {'node_1': 'microwave interferometry', 'node_2': 'diagnostic techniques', 'edge': 'includes'}, {'node_1': 'laser-induced fluorescence', 'node_2': 'diagnostic techniques', 'edge': 'includes'}, {'node_1': 'theoretical concepts', 'node_2': 'diagnostic techniques', 'edge': 'bridge between'}, {'node_1': 'practical applications', 'node_2': 'diagnostic techniques', 'edge': 'bridge between'}, {'node_1': 'Chapter 5', 'node_2': 'etching equipment geometries', 'edge': 'reviews'}, {'node_1': 'plasma processes', 'node_2': 'etching equipment geometries', 'edge': 'essential for controlling'}, {'node_1': 'plasma processes', 'node_2': 'ULSI device manufacturing', 'edge': 'used in'}, {'node_1': 'understanding', 'node_2': 'plasma processes', 'edge': 'crucial for optimizing plasma processes to achieve desired results'}, {'node_1': 'ULSI devices', 'node_2': 'plasma processes', 'edge': 'manufactured using'}]\n",
      ".[{'node_1': 'Theoretical Foundations', 'node_2': 'Practical Applications', 'edge': 'links'}, {'node_1': 'Semiconductor Fabrication', 'node_2': 'Semiconductor Processing', 'edge': 'applies to'}, {'node_1': 'Semiconductor Fabrication', 'node_2': 'Etching Equipment Geometries and Operation', 'edge': 'covers'}, {'node_1': 'Etching Equipment Geometries and Operation', 'node_2': 'Chapter 5', 'edge': 'is part of'}, {'node_1': 'Various etch configurations', 'node_2': 'Etching Equipment Geometries and Operation', 'edge': 'includes'}, {'node_1': 'Line profile control methods', 'node_2': 'Etching Equipment Geometries and Operation', 'edge': 'discusses'}, {'node_1': 'Ion Implantation in Semiconductor Fabrication', 'node_2': 'Chapter 6', 'edge': 'covers'}, {'node_1': 'Design', 'node_2': 'Broad-Beam Ion Sources', 'edge': 'includes'}, {'node_1': 'Construction', 'node_2': 'Broad-Beam Ion Sources', 'edge': 'includes'}, {'node_1': 'Operation', 'node_2': 'Broad-Beam Ion Sources', 'edge': 'covers'}, {'node_1': 'Techniques for integrating etching with growth or deposition processes', 'node_2': 'Broad-Beam Ion Sources', 'edge': 'presents'}, {'node_1': 'Occupational Health and Safety in Semiconductor Fabrication', 'node_2': 'Chapter 7', 'edge': 'covers'}, {'node_1': 'Safety issues', 'node_2': 'Chapter 7', 'edge': 'addresses'}, {'node_1': 'Handling of gases', 'node_2': 'Chapter 7', 'edge': 'discusses'}, {'node_1': 'Safe practices', 'node_2': 'Chapter 7', 'edge': 'provides techniques for'}]\n",
      ".[{'node_1': 'Plasma Etching', 'node_2': 'Microelectronics Fabrication Process', 'edge': 'is a crucial step in'}, {'node_1': 'Plasma Etching', 'node_2': 'Material Removal on Microscopic Scale', 'edge': 'precisely removes materials during'}, {'node_1': 'Plasma Etching', 'node_2': 'Critical Dimension Reduction', 'edge': 'is essential for enabling'}, {'node_1': 'Critical Dimension Reduction', 'node_2': 'Microelectronic Device Miniaturization', 'edge': 'is crucial for the miniaturization of'}, {'node_1': 'Plasma Etching', 'node_2': 'Increase in Device Functionality', 'edge': 'is essential for the increase in'}, {'node_1': 'Microelectronics Development', 'node_2': 'Plasma Etching Technology', 'edge': 'has been driven by advancements in'}, {'node_1': 'Microelectronics Development', 'node_2': 'Smaller, More Complex Devices', 'edge': 'enables the production of'}, {'node_1': 'Technological Evolution', 'node_2': 'Competitive Microelectronics Industry', 'edge': 'is a response to the competitive nature of'}, {'node_1': 'Plasma Etching Technology', 'node_2': 'Innovation and Efficiency', 'edge': 'is key to maintaining rapid innovation and efficiency in the industry'}, {'node_1': 'Authors', 'node_2': 'Colleagues and Students', 'edge': 'acknowledge constructive feedback and encouragement from'}, {'node_1': 'Plasma Etching Technology', 'node_2': 'Gas Handling (Inlet to Exhaust Stack)', 'edge': 'is crucial for handling gases from inlet to exhaust stack during microelectronics production'}]\n",
      "."
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(doc_list):\n",
    "    \n",
    "    graph_root=f'graph_{i}'\n",
    "    _graph_GraphML= f'{data_dir_output}/{graph_root}_augmented_graphML_integrated.graphml'\n",
    "    txt=''\n",
    "\n",
    "    if os.path.exists(_graph_GraphML):\n",
    "        G = nx.read_graphml(_graph_GraphML)\n",
    "        print(f'Main KG loaded: {_graph_GraphML}, {G}')\n",
    "        continue\n",
    "        \n",
    "    elif os.path.exists(f'{i}_err.txt'):\n",
    "        print(f'No. {i}: {doc} got something wrong.')\n",
    "        continue\n",
    "\n",
    "    elif os.path.exists(f'{data_dir}/graph_{i}_graph.graphml'):\n",
    "        print(f'Found a graph fragment to merge: {i}: {doc}.')\n",
    "        graph_GraphML = f'{data_dir}/graph_{i}_graph.graphml'\n",
    "    \n",
    "    else:\n",
    "        print(f'Generating a knowledge graph from {doc}')\n",
    "        with open(doc, \"r\") as f:\n",
    "            txt = \" \".join(f.read().splitlines())  # separate lines with a single space\n",
    "\n",
    "        try:\n",
    "            _, graph_GraphML, _, _, _ = make_graph_from_text(txt,generate_Mistral,\n",
    "                                  include_contextual_proximity=False,\n",
    "                                  graph_root=graph_root,\n",
    "                                  chunk_size=1000,chunk_overlap=200,\n",
    "                                  repeat_refine=0,verbatim=False,\n",
    "                                  data_dir=data_dir,\n",
    "                                  save_PDF=False,#TO DO\n",
    "                                 )\n",
    "        except Exception as e:\n",
    "            print(f'Something is wrong with No. {i}: {doc}.')\n",
    "            f = open(f'{i}_err.txt', 'w')\n",
    "            f.write(f'{e}\\n{doc}\\n{txt}')\n",
    "            f.close()          \n",
    "            continue\n",
    "        print(f'Merging graph No. {i}: {doc} to the main one')\n",
    "    \n",
    "    try:\n",
    "        _, G, _, node_embeddings, res = add_new_subgraph_from_text(txt, generate_Mistral,\n",
    "                           node_embeddings, embedding_tokenizer, embedding_model,\n",
    "                           original_graph=G, data_dir_output=data_dir_output, graph_root=graph_root,\n",
    "                           chunk_size=1000,chunk_overlap=200,\n",
    "                           do_simplify_graph=True,size_threshold=10,\n",
    "                           repeat_refine=0,similarity_threshold=0.95,\n",
    "                           do_Louvain_on_new_graph=True, include_contextual_proximity=False,\n",
    "                           #whether or not to simplify, uses similiraty_threshold defined above\n",
    "                           return_only_giant_component=False,\n",
    "                           save_common_graph=False,G_to_add=None,graph_GraphML_to_add=graph_GraphML,\n",
    "                           verbatim=True,)\n",
    "\n",
    "        save_embeddings(node_embeddings, f'{data_dir}/{embedding_file}')\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263631d-e3ac-4def-9bec-2b46b5bf27a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml(f'{data_dir}/graph_0_graph.graphml')\n",
    "print(f'KG loaded: {G}')\n",
    "# node_embeddings = generate_node_embeddings(G, embedding_tokenizer, embedding_model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08c7c6-7b29-4248-9443-7c3e3a6fc29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def split_documents_into_chunks(documents, chunk_size=600, overlap_size=100):\n",
    "#     chunks = []\n",
    "#     for document in documents:\n",
    "#         for i in range(0, len(document), chunk_size - overlap_size):\n",
    "#             chunk = document[i:i + chunk_size]\n",
    "#             chunks.append(chunk)\n",
    "#     return chunks\n",
    "\n",
    "# def extract_elements_from_chunks(chunks):\n",
    "#     elements = []\n",
    "#     for index, chunk in enumerate(chunks):\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"Extract entities and relationships from the following text.\"},\n",
    "#                 {\"role\": \"user\", \"content\": chunk}\n",
    "#             ]\n",
    "#         )\n",
    "#         entities_and_relations = response.choices[0].message.content\n",
    "#         elements.append(entities_and_relations)\n",
    "#     return elements\n",
    "\n",
    "# def summarize_elements(elements):\n",
    "#     summaries = []\n",
    "#     for index, element in enumerate(elements):\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"Summarize the following entities and relationships in a structured format. Use \\\"->\\\" to represent relationships, after the \\\"Relationships:\\\" word.\"},\n",
    "#                 {\"role\": \"user\", \"content\": element}\n",
    "#             ]\n",
    "#         )\n",
    "#         summary = response.choices[0].message.content\n",
    "#         summaries.append(summary)\n",
    "#     return summaries\n",
    "\n",
    "# def build_graph_from_summaries(summaries):\n",
    "#     G = nx.Graph()\n",
    "#     for summary in summaries:\n",
    "#         lines = summary.split(\"\\n\")\n",
    "#         entities_section = False\n",
    "#         relationships_section = False\n",
    "#         entities = []\n",
    "#         for line in lines:\n",
    "#             if line.startswith(\"### Entities:\") or line.startswith(\"**Entities:**\"):\n",
    "#                 entities_section = True\n",
    "#                 relationships_section = False\n",
    "#                 continue\n",
    "#             elif line.startswith(\"### Relationships:\") or line.startswith(\"**Relationships:**\"):\n",
    "#                 entities_section = False\n",
    "#                 relationships_section = True\n",
    "#                 continue\n",
    "#             if entities_section and line.strip():\n",
    "#                 entity = line.split(\".\", 1)[1].strip() if line[0].isdigit() and line[1] == \".\" else line.strip()\n",
    "#                 entity = entity.replace(\"**\", \"\")\n",
    "#                 entities.append(entity)\n",
    "#                 G.add_node(entity)\n",
    "#             elif relationships_section and line.strip():\n",
    "#                 parts = line.split(\"->\")\n",
    "#                 if len(parts) >= 2:\n",
    "#                     source = parts[0].strip()\n",
    "#                     target = parts[-1].strip()\n",
    "#                     relation = \" -> \".join(parts[1:-1]).strip()\n",
    "#                     G.add_edge(source, target, label=relation)\n",
    "#     return G\n",
    "\n",
    "def detect_communities(graph):\n",
    "    # communities = []\n",
    "#     for component in nx.weakly_connected_components(graph):\n",
    "#         subgraph = graph.subgraph(component)\n",
    "#         if len(subgraph.nodes) > 1:\n",
    "#             try:\n",
    "#                 # sub_communities = algorithms.leiden(subgraph)\n",
    "#                 sub_communities = nx.community.girvan_newman(subgraph)\n",
    "                \n",
    "#                 # for community in sub_communities.communities:\n",
    "#                 for community in tqdm(sub_communities):\n",
    "#                     communities.append(list(community))\n",
    "       \n",
    "#                 communities = sorted(map(sorted, next_level_communities))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing community: {e}\")\n",
    "#         else:\n",
    "#             communities.append(list(subgraph.nodes))\n",
    "\n",
    "    communities_generator = nx.community.girvan_newman(G)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    communities = sorted(map(sorted, next_level_communities))\n",
    "    return communities\n",
    "\n",
    "def summarize_communities(communities, graph, generate):\n",
    "    community_summaries = []\n",
    "    for index, community in tqdm(enumerate(communities)):\n",
    "        subgraph = graph.subgraph(community)\n",
    "        nodes = list(subgraph.nodes)\n",
    "        edges = list(subgraph.edges(data=True))\n",
    "        description = \"Entities: \" + \", \".join(nodes) + \"\\nRelationships: \"\n",
    "        relationships = []\n",
    "        for edge in edges:\n",
    "            relationships.append(\n",
    "                f\"{edge[0]} -> {edge[2]['title']} -> {edge[1]}\")\n",
    "        description += \", \".join(relationships)\n",
    "        try:\n",
    "            response = generate(system_prompt= \"Summarize the following community of entities and relationships.\",\n",
    "                                       prompt= description)\n",
    "        # response = client.chat.completions.create(\n",
    "        #     model=\"gpt-4\",\n",
    "        #     messages=[\n",
    "        #         {\"role\": \"system\", \"content\": \"Summarize the following community of entities and relationships.\"},\n",
    "        #         {\"role\": \"user\", \"content\": description}\n",
    "        #     ]\n",
    "        # )\n",
    "        # summary = response.choices[0].message.content.strip()\n",
    "        except:\n",
    "            print(description)\n",
    "        summary = response.strip()\n",
    "        community_summaries.append(summary)\n",
    "    return community_summaries\n",
    "\n",
    "def generate_answers_from_communities(community_summaries, generate, query):\n",
    "    intermediate_answers = []\n",
    "    for summary in tqdm(community_summaries):\n",
    "        try:\n",
    "            response = generate(system_prompt= \"Answer the following query based on the provided summary.\",\n",
    "                                       prompt=f\"Query: {query} Summary: {summary}\")\n",
    "            # response = client.chat.completions.create(\n",
    "            #     model=\"gpt-4\",\n",
    "            #     messages=[\n",
    "            #         {\"role\": \"system\", \"content\": \"Answer the following query based on the provided summary.\"},\n",
    "            #         {\"role\": \"user\", \"content\": f\"Query: {query} Summary: {summary}\"}\n",
    "            #     ]\n",
    "            # )\n",
    "            intermediate_answers.append(response)\n",
    "        except:\n",
    "            print(f'TL;DR: {summary[0:100]}...{summary[-100:]}')\n",
    "            return 0\n",
    "    final_response = generate(system_prompt= \"Combine these answers into a final, concise response.\",\n",
    "                                prompt=f\"Intermediate answers: {' '.join(intermediate_answers)}\")\n",
    "\n",
    "    # final_response = client.chat.completions.create(\n",
    "    #     model=\"gpt-4\",\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": \"Combine these answers into a final, concise response.\"},\n",
    "    #         {\"role\": \"user\", \"content\": }\n",
    "    #     ]\n",
    "    # )\n",
    "    # final_answer = final_response.choices[0].message.content\n",
    "    return final_response\n",
    "\n",
    "# def graph_rag_pipeline(documents, query, chunk_size=600, overlap_size=100):\n",
    "def graph_rag_pipeline(graph, generate, query):\n",
    "    # chunks = split_documents_into_chunks(documents, chunk_size, overlap_size)\n",
    "    # elements = extract_elements_from_chunks(chunks)\n",
    "    # summaries = summarize_elements(elements)\n",
    "    # graph = build_graph_from_summaries(summaries)\n",
    "    \n",
    "    communities = detect_communities(graph)\n",
    "    if verbatim:\n",
    "        print(\"Number of Communities = \", len(communities))\n",
    "    community_summaries = summarize_communities(communities, graph, generate)\n",
    "    final_answer = generate_answers_from_communities(community_summaries, generate, query)\n",
    "    return final_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cb9e9-af69-4ba6-a987-25c05ad886f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph=G\n",
    "generate = generate_Mistral\n",
    "communities = detect_communities(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63873d32-20d6-4671-9bb0-c456ad56df90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "community_summaries = summarize_communities(communities, graph, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ba938-cee4-415e-947d-e0565f086aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "community_summaries_sorted = sorted(community_summaries, key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69e070-7984-4da7-8f14-229cf0343544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What are the main techniques to make semiconductors?\"\n",
    "\n",
    "last_response=''\n",
    "for i, summary in tqdm(enumerate(community_summaries_sorted)):\n",
    "    response = generate(system_prompt= \"Answer the query detailedly based on the collected information and the combined with the last thought you have. \",\n",
    "                               prompt=f\"Query: {query} Collected information: {summary} You last thought: {last_response}\")\n",
    "    last_response=response\n",
    "    print(last_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84f00a-e452-4082-b23f-f7f0cf60a419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eca421-f4da-41a2-9303-74dc57e290ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_response = generate(system_prompt= \"Combine these answers into a final, concise response.\",\n",
    "                            prompt=f\" answers: {last_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response, (best_node_1, best_similarity_1, best_node_2, best_similarity_2), path, path_graph, shortest_path_length, fname, graph_GraphML = find_path_and_reason(\n",
    "#     G, \n",
    "#     node_embeddings,\n",
    "#     embedding_tokenizer, \n",
    "#     embedding_model, \n",
    "#     generate_Mistral, \n",
    "#     data_dir=data_dir_output,\n",
    "#     verbatim=verbatim,\n",
    "#     include_keywords_as_nodes=True,  # Include keywords in the graph analysis\n",
    "#     keyword_1=\"semiconductors\",\n",
    "#     keyword_2=\"etching\",\n",
    "#     N_limit=9999,  # The limit for keywords, triplets, etc.\n",
    "#     instruction='What is the best etching method to manufacture semiconductors.',\n",
    "#     keywords_separator=', ',\n",
    "#     graph_analysis_type='nodes and relations',\n",
    "#     temperature=0.3, \n",
    "#     inst_prepend='### ',  # Instruction prepend text\n",
    "#     prepend='''You are given a set of information from a graph that describes the relationship \n",
    "#                between materials and manufacturing process. You analyze these logically \n",
    "#                through reasoning.\\n\\n''',  # Prepend text for analysis\n",
    "#     visualize_paths_as_graph=True,  # Whether to visualize paths as a graph\n",
    "#     display_graph=True,  # Whether to display the graph\n",
    "# )\n",
    "# display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response, (best_node_1, best_similarity_1, best_node_2, best_similarity_2), path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434a729-4756-47ca-988c-c2e0e6ec7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_2d_pretty_and_sample(node_embeddings, n_clusters=10, n_samples=10, data_dir=data_dir_output, alpha=.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111b640-7a92-4357-ab62-32621999f4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe_communities_with_plots_complex(G, N=6, data_dir=data_dir_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3279fbe-e558-445f-9829-c7912fdff04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# graph_statistics_and_plots_for_large_graphs(G, data_dir=data_dir_output,include_centrality=False,\n",
    "                                               # make_graph_plot=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f82e50-44bb-4b34-8953-91e2b287f68d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "is_scale_free (G, data_dir=data_dir_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd8547-9599-41c1-a1df-e011c8090307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_fitting_node_list(\"semiconductor\", node_embeddings, embedding_tokenizer, embedding_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3726c6-defc-426d-8d10-a5ac7b77c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_fitting_node_list(\"better manufactoring process for semiconductor\", node_embeddings , embedding_tokenizer, embedding_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53de6b-0929-47a9-a9f3-9fa0b6bb77d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ee778-2838-4045-b0b6-0c2f09832947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (best_node_1, best_similarity_1, best_node_2, best_similarity_2), path, path_graph, shortest_path_length, fname, graph_GraphML=find_path( G, node_embeddings,\n",
    "                                # embedding_tokenizer, embedding_model , second_hop=False, data_dir=data_dir_output,\n",
    "                                #   keyword_1 = \"new materials\", keyword_2 = \"semiconductor\",\n",
    "                                #       similarity_fit_ID_node_1=0, similarity_fit_ID_node_2=0,\n",
    "                                #        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ee0bb-1925-42b2-819c-90ca745ba47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf71de-038b-4b66-ac58-232c4fc4476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273351c-a0c6-4b31-bec5-658a84b27bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_list, path_string=print_path_with_edges_as_list(G , path)\n",
    "# path_list,path_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d8867-2749-4f7b-993d-dc3287db8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_paths_pretty([path_list], 'knowledge_graph_paths.svg', display_graph=True,data_dir=data_dir_output, scale=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f83f5-b43d-45ce-8b0c-57a57a1a937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplets=find_all_triplets(path_graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d054dfc-a0d6-4a12-9905-ab264c8d9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e52df-60c8-4d9a-87ef-1f566bf88f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d07c7-250e-4a6b-9ee9-b5e327d7942a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
